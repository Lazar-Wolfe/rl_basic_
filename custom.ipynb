{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete(n).sample() gives values [0,n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box(l,r,shape=(r,c)) give rxc matrix of random numbers in [l,r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8348152 , 0.999604  , 0.27463803],\n",
       "       [0.782614  , 0.68793845, 0.9758288 ],\n",
       "       [0.854323  , 0.4515435 , 0.94891465]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1,shape=(3,3)).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict is like a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('a', 0),\n",
       "             ('b', array([[74, 41, 51],\n",
       "                     [35, 76, 54],\n",
       "                     [55, 28, 72]]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({\"a\": Discrete(3), \"b\": Box(0,100,shape=(3,3),dtype=int)}).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multibinary(n) gives n random binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiDiscrete([a,b,c]) give x,y,z random values in [0,a-1], [0,b-1], [0,c-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([2,3,4]).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Environment <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(low=0,high = 100,shape =(1,))\n",
    "        self.state = 38+random.randint(-3,3)\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.state+=action-1\n",
    "\n",
    "        self.shower_length -=1\n",
    "\n",
    "        # REWARD    \n",
    "        if self.state >= 37 and self.state <= 39:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        # TERMINAL\n",
    "        if self.shower_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        info ={}\n",
    "        \n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 38+random.randint(-3,3)\n",
    "        self.shower_length = 60\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.8683991], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 score -60\n",
      "Episode 2 score -30\n",
      "Episode 3 score -56\n",
      "Episode 4 score -28\n",
      "Episode 5 score -38\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1,episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score =0\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        # print(obs,reward,done,info)\n",
    "    print(f\"Episode {episode} score {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training','Logs')\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_7\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -28.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 1120     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -26.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 834         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013244765 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -2.65e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    value_loss           | 80.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -25.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 758         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005125424 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.986      |\n",
      "|    explained_variance   | -5.72e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 71.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -24.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052279206 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.966       |\n",
      "|    explained_variance   | -3.54e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.5         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000886    |\n",
      "|    value_loss           | 94           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -28          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067560906 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.952       |\n",
      "|    explained_variance   | 0.00147      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000644    |\n",
      "|    value_loss           | 68.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -26.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 590        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00918607 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.984     |\n",
      "|    explained_variance   | 0.00436    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.4       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    value_loss           | 65.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -25.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 576          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076897014 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.986       |\n",
      "|    explained_variance   | 0.00288      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.3         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 89.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 60            |\n",
      "|    ep_rew_mean          | -24.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 587           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021054738 |\n",
      "|    clip_fraction        | 0.053         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.976        |\n",
      "|    explained_variance   | -0.0159       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 45.3          |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00523      |\n",
      "|    value_loss           | 91            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -24.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 583          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034994404 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.941       |\n",
      "|    explained_variance   | -1.84e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.7         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000456    |\n",
      "|    value_loss           | 79.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -24.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 555          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041502835 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | -5.6e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49           |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    value_loss           | 94.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009809189 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 1.88e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -14.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 567        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00638254 |\n",
      "|    clip_fraction        | 0.086      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.726     |\n",
      "|    explained_variance   | 0.000154   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.8       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00917   |\n",
      "|    value_loss           | 97.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -17         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003949638 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.00538     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 84.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -16          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 585          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027358872 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.645       |\n",
      "|    explained_variance   | 0.00793      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00076     |\n",
      "|    value_loss           | 95.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -18.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 598          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033582426 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | -0.014       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 86.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -13.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 580          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012928867 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.58        |\n",
      "|    explained_variance   | -0.00418     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.8         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | 0.00051      |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -16.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006305958 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.00119     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.000174   |\n",
      "|    value_loss           | 90.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -14.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037558994 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.628       |\n",
      "|    explained_variance   | -0.00798     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 46.2         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    value_loss           | 90.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -14.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015583795 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.637       |\n",
      "|    explained_variance   | 0.00483      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.2         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | 7.57e-05     |\n",
      "|    value_loss           | 89.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -16.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 557          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029653655 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.0174       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 95.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -16.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002880273 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | -0.015      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    value_loss           | 85.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -18.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 575          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019506991 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.00308      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.6         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -9.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 580          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013475604 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 9.26e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.5         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | 0.000417     |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -10.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 565          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033917124 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | -0.0089      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | 0.000301     |\n",
      "|    value_loss           | 98.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -8.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 555          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052969586 |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0005       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.8         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 92.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x25db66d52b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_path = os.path.join('Training','Saved_Models','Shower_Model_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-24.0, 54.99090833947008)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(shower_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
